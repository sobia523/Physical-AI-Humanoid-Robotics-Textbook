# Research & Decisions: RAG Ingestion Pipeline

This document records the key technical decisions made during the planning phase for the content ingestion pipeline.

## R-01: HTML Parsing Library

- **Decision**: Use `BeautifulSoup` for HTML parsing.
- **Rationale**: 
  - `BeautifulSoup` is highly robust and adept at handling messy, real-world HTML, which is a key requirement when scraping a deployed website.
  - Its API is more intuitive and easier to use for the required task of extracting specific content blocks (e.g., the main article body) while stripping away navigation and other boilerplate.
  - While `lxml` is faster, the performance difference is not critical for this offline batch processing pipeline. Robustness and ease of development are prioritized.
- **Alternatives considered**:
  - `lxml`: A high-performance parser, but it is stricter and can be more complex to use for scraping tasks where the HTML structure isn't perfectly controlled.

## R-02: Content Chunking Strategy

- **Decision**: Implement a recursive, semantic chunking strategy based on HTML headings.
- **Rationale**:
  - For technical documentation, semantic boundaries (headings, sub-headings) are crucial for preserving context. A simple fixed-size chunk could split a code block or a critical explanation, reducing the quality of the retrieved context.
  - The strategy will be to first split the document by major headings (e.g., `<h1>`, `<h2>`). If a resulting chunk is still larger than the target size, it will be recursively split by smaller headings (`<h3>`, `<h4>`) and then by paragraphs if necessary.
  - This approach directly supports future requirements like "answer from selected text only" and improves citation accuracy by keeping related text together.
- **Initial Parameters**:
  - **Target Chunk Size**: ~512 tokens. This is a common size that fits well within the context windows of many models.
  - **Chunk Overlap**: ~50 tokens. A small overlap helps maintain context between chunks without introducing too much redundant data.
- **Alternatives considered**:
  - **Fixed-size chunking**: Simpler to implement but semantically naive. It often leads to poor context quality for retrieval.
  - **Sentence-based chunking**: Can be too granular and may lose broader context from the surrounding paragraphs.

## R-03: Qdrant Vector Database Configuration

- **Decision**:
  - **Distance Metric**: `Cosine Similarity`.
  - **Payload Indexing**: Create indexes on `source_url` and `section` fields.
- **Rationale**:
  - Cosine similarity is the standard and recommended distance metric for comparing text embeddings generated by models like Cohere's, as it measures the orientation (semantic similarity) rather than the magnitude of the vectors.
  - Indexing the metadata fields from the start will allow for efficient filtering in the future (e.g., "search only within Module 3"). While not a requirement for the initial implementation, designing for it now is a trivial cost with significant future benefits.
- **Alternatives considered**:
  - **Dot Product / Euclidean Distance**: These are less effective for normalized transformer-based embeddings where vector direction is the primary carrier of semantic information.
